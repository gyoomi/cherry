- 计算机中存储信息的最小单元是一个字节即 8 个 bit，所以能表示的字符范围是 0~255 个 
人类要表示的符号太多，无法用一个字节来完全表示 
要解决这个矛盾必须需要一个新的数据结构 char，从 char 到 byte 必须编码 
如何“翻译” 
- 明白了各种语言需要交流，经过翻译是必要的，那又如何来翻译呢？计算中提拱了多种翻译方式，常见的有 ASCII、ISO-8859-1、GB2312、GBK、UTF-8、UTF-16 等。它们都可以被看作为字典，它们规定了转化的规则，按照这个规则就可以让计算机正确的表示我们的字符。目前的编码格式很多，例如 GB2312、GBK、UTF-8、UTF-16 这几种格式都可以表示一个汉字，那我们到底选择哪种编码格式来存储汉字呢？这就要考虑到其它因素了，是存储空间重要还是编码的效率重要。根据这些因素来正确选择编码格式，下面简要介绍一下这几种编码格式。 
ASCII 码 
- 学过计算机的人都知道 ASCII 码，总共有 128 个，用一个字节的低 7 位表示，0~31 是控制字符如换行回车删除等；32~126 是打印字符，可以通过键盘输入并且能够显示出来。 
ISO-8859-1 
128 个字符显然是不够用的，于是 ISO 组织在 ASCII 码基础上又制定了一些列标准用来扩展 ASCII 编码，它们是 ISO-8859-1~ISO-8859-15，其中 ISO-8859-1 涵盖了大多数西欧语言字符，所有应用的最广泛。ISO-8859-1 仍然是单字节编码，它总共能表示 256 个字符。 
GB2312 
它的全称是《信息交换用汉字编码字符集 基本集》，它是双字节编码，总的编码范围是 A1-F7，其中从 A1-A9 是符号区，总共包含 682 个符号，从 B0-F7 是汉字区，包含 6763 个汉字。 
GBK 
全称叫《汉字内码扩展规范》，是国家技术监督局为 windows95 所制定的新的汉字内码规范，它的出现是为了扩展 GB2312，加入更多的汉字，它的编码范围是 8140~FEFE（去掉 XX7F）总共有 23940 个码位，它能表示 21003 个汉字，它的编码是和 GB2312 兼容的，也就是说用 GB2312 编码的汉字可以用 GBK 来解码，并且不会有乱码。 
GB18030 
全称是《信息交换用汉字编码字符集》，是我国的强制标准，它可能是单字节、双字节或者四字节编码，它的编码与 GB2312 编码兼容，这个虽然是国家标准，但是实际应用系统中使用的并不广泛。 
UTF-16 
说到 UTF 必须要提到 Unicode（Universal Code 统一码），ISO 试图想创建一个全新的超语言字典，世界上所有的语言都可以通过这本字典来相互翻译。可想而知这个字典是多么的复杂，关于 Unicode 的详细规范可以参考相应文档。Unicode 是 Java 和 XML 的基础，下面详细介绍 Unicode 在计算机中的存储形式。 
UTF-16 具体定义了 Unicode 字符在计算机中存取方法。UTF-16 用两个字节来表示 Unicode 转化格式，这个是定长的表示方法，不论什么字符都可以用两个字节表示，两个字节是 16 个 bit，所以叫 UTF-16。UTF-16 表示字符非常方便，每两个字节表示一个字符，这个在字符串操作时就大大简化了操作，这也是 Java 以 UTF-16 作为内存的字符存储格式的一个很重要的原因。 
UTF-8 
UTF-16 统一采用两个字节表示一个字符，虽然在表示上非常简单方便，但是也有其缺点，有很大一部分字符用一个字节就可以表示的现在要两个字节表示，存储空间放大了一倍，在现在的网络带宽还非常有限的今天，这样会增大网络传输的流量，而且也没必要。而 UTF-8 采用了一种变长技术，每个编码区域有不同的字码长度。不同类型的字符可以是由 1~6 个字节组成。 
UTF-8 有以下编码规则： 
如果一个字节，最高位（第 8 位）为 0，表示这是一个 ASCII 字符（00 - 7F）。可见，所有 ASCII 编码已经是 UTF-8 了。 
如果一个字节，以 11 开头，连续的 1 的个数暗示这个字符的字节数，例如：110xxxxx 代表它是双字节 UTF-8 字符的首字节。 
如果一个字节，以 10 开始，表示它不是首字节，需要向前查找才能得到当前字符的首字节 
Java 中需要编码的场景 
前面描述了常见的几种编码格式，下面将介绍 Java 中如何处理对编码的支持，什么场合中需要编码。 
I/O 操作中存在的编码 
我们知道涉及到编码的地方一般都在字符到字节或者字节到字符的转换上，而需要这种转换的场景主要是在 I/O 的时候，这个 I/O 包括磁盘 I/O 和网络 I/O，关于网络 I/O 部分在后面将主要以 Web 应用为例介绍。

windows系统中ANSI一般指在地化的字符集及其编码方式，根据系统版本及相关语言选项而有所不同，&H7F以内采用ASCII编码，在简中环境一般还包括GB2312及后来的GBK、GB18030编码（这三个为字符集，但通常也隐含EUC-CN编码的含义），利用的是ASCII扩展编码空间，即所谓制表符（该空间也包含拉丁、希腊字母等非英文字符），因此包含有表格字符的文本在简中环境下，表格部分常常会被显示成汉字。实际上狭义的ANSI编码应该就是所谓ASCII及其扩展码部分，记事本等地方出现的ANSI是极不严谨的。Unicode是国际标准的字符集，在windows中常常也特指UTF-16（el小头）编码，每个字符占俩字节。UTF-8则字符所占长度为变长。实际上windows及微软其他软件中，很多表述不是特别严谨，比如ASC()函数，该函数原本指取首字符的ASCII码值，而描述中是取首字符的ANSI码值，但在VB中参量为中文字符的时候和在老版本BASIC中返回的结果却大不同，老版本为&H80到&HFF之间，而VB中返回的却为UTF-16码值。就兼容及经济性来讲，不同的环境这几种编码各有优缺点。兼容性来说其实对我来说差不多，只要尽量使用同一种编码就不会对我产生困扰，具体还要考虑到所用到的软件环境兼容哪一种。而经济性么，源代码、网页代码之类的东西用utf-8看起来比较经济，但对于中文为主的文本性的内容而言（例如文学作品等），双字节的UTF-16更省，而且个人感觉UTF16的文件很整齐，计数和查找比较方便。“ANSI”则对较老的环境兼容性很好，也不存在BOM，在不涉及复杂多语言环境的情况下也是个不错的选择。